import os
import sys
import fileinput
# from nltk.tokenize import WhitespaceTokenizer
#try with pycontractions
import contractions 
import re

tokens = { 
"ain't": "am not",
"aren't": "are not",
"can't": "cannot",
"can't've": "cannot have",
"'cause": "because",
"could've": "could have",
"couldn't": "could not",
"couldn't've": "could not have",
"didn't": "did not",
"doesn't": "does not",
"don't": "do not",
"hadn't": "had not",
"hadn't've": "had not have",
"hasn't": "has not",
"haven't": "have not",
"he'd": "he would",
"he'd've": "he would have",
"he'll": "he will",
"he'll've": "he will have",
"he's": "he is",
"how'd": "how did",
"how'd'y": "how do you",
"how'll": "how will",
"how's": "how is",
"I'd": "I had",
"I'd've": "I would have",
"I'll": "I will",
"I'll've": "I will have",
"I'm": "I am",
"I've": "I have",
"isn't": "is not",
"it'd": "it would",
"it'd've": "it would have",
"it'll": "it will",
"it'll've": "it will have",
"it's": "it is",
"let's": "let us",
"ma'am": "madam",
"mayn't": "may not",
"might've": "might have",
"mightn't": "might not",
"mightn't've": "might not have",
"must've": "must have",
"mustn't": "must not",
"mustn't've": "must not have",
"needn't": "need not",
"needn't've": "need not have",
"o'clock": "of the clock",
"oughtn't": "ought not",
"oughtn't've": "ought not have",
"shan't": "shall not",
"sha'n't": "shall not",
"shan't've": "shall not have",
"she'd": "she would",
"she'd've": "she would have",
"she'll": "she will",
"she'll've": "she will have",
"she's": "she is",
"should've": "should have",
"shouldn't": "should not",
"shouldn't've": "should not have",
"so've": "so have",
"so's": "so is",
"that'd": "that would",
"that'd've": "that would have",
"that's": "that is",
"there'd": "there would",
"there'd've": "there would have",
"there's": "there is",
"they'd": "they would",
"they'd've": "they would have",
"they'll": "they will",
"they'll've": "they will have",
"they're": "they are",
"they've": "they have",
"to've": "to have",
"wasn't": "was not",
"we'd": "we would",
"we'd've": "we would have",
"we'll": "we will",
"we'll've": "we will have",
"we're": "we are",
"we've": "we have",
"weren't": "were not",
"what'll": "what will",
"what'll've": "what will have",
"what're": "what are",
"what's": "what is",
"what've": "what have",
"when's": "when is",
"when've": "when have",
"where'd": "where did",
"where's": "where is",
"where've": "where have",
"who'll": "who will",
"who'll've": " who will have",
"who's": "who is",
"who've": "who have",
"why's": "why is",
"why've": "why have",
"will've": "will have",
"won't": "will not",
"won't've": "will not have",
"would've": "would have",
"wouldn't": "would not",
"wouldn't've": "would not have",
"y'all": "you all",
"y'all'd": "you all would",
"y'all'd've": "you all would have",
"y'all're": "you all are",
"y'all've": "you all have",
"you'd": "you would",
"you'd've": "you would have",
"you'll": "you will",
"you'll've": "you will have",
"you're": "you are",
"you've": "you have",
"everybody's":"everybody is",
"something's":"something is",
"somebody's":"somebody is",
"someone's":"someone is",
"everyone's":"everyone is",
"someone's":"someone is",
"everything's":"everything is",
"Student:": "<Student:>",
"SPEAKER:":"<Speaker:>",
"BRIAN YU:":"<BRIAN YU:>",
"DAVID J. MALAN:":"<DAVID J. MALAN:>",
"RAFAEL IRIZARRY:":"<RAFAEL IRIZARRY: >",
"DAVID MALAN: ":"<DAVID MALAN: >",
"COLTON OGDEN:":"<COLTON OGDEN:>",
"TEJEEV KOHLI:":"<TEJEEV KOHLI:>",
"DAVE KIRCHER:":"<DAVE KIRCHER:>",
"PATRICK PENNEFATHER: ":"<PATRICK PENNEFATHER: >",
"BRENT STEVENSON: ":"<BRENT STEVENSON: >",
"KIMBERLY VOLL: ":"<KIMBERLY VOLL: >",
"KIRSTEN WICKLUND:":"<KIRSTEN WICKLUND:>",
"ANDY MOORE: ":"<ANDY MOORE: >",
"ALANA THORBURN-WATT: ":"<ALANA THORBURN-WATT: >",
"LEONARD VOGT:":"<LEONARD VOGT:>",
"LEN VOGT: ":"<LEN VOGT: >",
"PROF IAIN MURRAY: ":"<PROF IAIN MURRAY: >",
"HIMANSHU AGRAWAL: ":"<HIMANSHU AGRAWAL: >",
"TESSA: ":"<TESSA: >",
"FROUKJE:":"<FROUKJE:>",
"PIETER: ":"<PIETER: >",
"ARMAGAN: ":"<ARMAGAN: >",
"MARIJKE: ":"<MARIJKE: >",
"MICHAEL LOVE: ":"<MICHAEL LOVE: >",
"IAIN MURRAY: ":"<IAIN MURRAY: >",
"WINDHYA RANKOTHGE: ":"<WINDHYA RANKOTHGE: >",
"PRAMODH:":"<PRAMODH:>",
"YUFENG GUO: ":"<YUFENG GUO: >",
"HIMANSHU: ":"<HIMANSHU: >",
"NAZANIN: ":"<NAZANIN: >",
"PRANAV:":"<PRANAV:>",
"PETER: ":"<PETER: >",
"IRIS":"<IRIS>",
"DAX: ":"<DAX: >",
"LEO: ":"<LEO: >",
"JASMINE: ":"<JASMINE: >",
"JENNY: ":"<JENNY: >",
"JORDAN HAYASHI: ":"<JORDAN HAYASHI: >",
"JORDAN: ":"<JORDAN: >",
"SAM: ":"<SAM: >",
"OMAR: ":"<OMAR: >",
"BRIAN:":"<BRIAN:>",
"SOPHIA: ":"<SOPHIA: >",
"SANTIAGO: ":"<SANTIAGO: >",
"LEXLENE: ":"<LEXLENE: >",
"JACOB: ":"<JACOB: >",
"JACK":"<JACK: >",
"ANDREW: ":"<ANDREW: >",
"RYAN: ":"<RYAN: >",
"NINA: ":"<NINA: >",
"OLIVIA: ":"<OLIVIA: >",
"ALEXANDRA:":"<ALEXANDRA>",
"JONATHAN:":"<JONATHAN>",
"TUCKER:":"<TUCKER:>",
"NICHOLAS:":"<NICHOLAS:>",
"DAVID J MALAN:":"<DAVID J MALAN:>",
"(HIGH PITCHED) ":" ",
"[pseudo code]":" ",
"[decentralized exchanges]":" ",
"[Explosion of altcoins]":" ",
"[decentralized exchanges]":" ",
"[TYPING]":" ",
"[Parity]":" ",
"[Parity 2]":" ",
"[Parity 3]":" ",
"[Coincheck]":" ",
"[Narrator] ":" ",
"[Instructor]":" ",
"[LAUGHING]":" ",
"[CHUCKLES]":" ",
"[APPLAUSE]":" ",
"[C MAJOR CHORD]":" ",
"[SILENCE]":" ",
"[BIRDS CHIRPING]":" ",
"[TRAIN WHISTLE]":" ",
"[END PLAYBACK]":" ",
"[SEQUENTIAL NOTES PLAY]":" ",
"[F SHARP]":" ",
"[MEOW] ":" ",
"[SEA LION BARKING] ":"<[SEA LION BARKING] >",
"[CHOMPING SOUNDS] ":" ",
"[SCREAMING] ":" ",
"[CACKLING] ":" ",
"[AUDIO PLAYBACK]":" ",
"[BEEPING]":" ",
"[spread] ":" spread ",
"SPEAKER 1:":"<SPEAKER 1:>",
"SPEAKER 2:":"<SPEAKER 2:>",
"SPEAKER 3:":"<SPEAKER 3:>",
"AUDIENCE:":"<AUDIENCE:>",
"COMPUTER: ":"<COMPUTER: >",
"Dr. Agarwal:":"<Dr. Agarwal:>",
"ANANT AGARWAL:":"<ANANT AGARWAL:>",
"PIOTR MITROS:":"<PIOTR MITROS: >",
"C++":"<C++>",
"i++":"<i++>",
"re-submit":"resubmit",
"[RADIO CHATTER] ":" ",
"[CLANGING] ":" ",
"[BARKING] ":" ",
"- (ON RADIO) ":" ",
"[FOOTSTEPS AND PANTING] ":" ",
"[MUSIC PLAYING]":" ",
"[PHONE RINGING] ":" ",
"[VIDEO PLAYBACK] ":" ",
"[SIGH] ":" ",
"[POP] ":" ",
"[HORN]":" ",
"[MUSIC]":" ",
"[INAUDIBLE]":" ",
"[COUGHING]":" ",
"[UNINTELLIGIBLE] ":" ",
"[PIANO MUSIC PLAYING]":" ",
"[TURNS ON DRYER]":" ",
"[PAUSE]":" ",
"[CHEERS]":" ",
"[CHAIN SAW]":" ",
"[more people talking]":" ",
"[Background noise]":" ",
"[MUSIC CONTINUES, SLIGHT STATIC]":" ",
"[MUSIC GETS CLEARER, LOUDER]":" ",
"[INTERPOSING VOICES]":" ",
"[WHIRRING SOUND]":" ",
"[?":" ",
"?]":" ",
"(upbeat music)":" ",
"HTTPS://google.com":"<HTTPS://google.com>",
"ControlLED_BusIO":"<ControlLED_BusIO>",
"ControlLED_DigitalIO":"<ControlLED_DigitalIO>",
"RED_LED":"<RED_LED>",
"-based":" based",
"re-":"re",
"real-time":"real time",
"-on":" on",
"-in ":" in ",
"-off":" off",
"-like":" like",
"-related":" related",
"-unit":" unit",
"-step":" step",
"-column":" column",
"-row":" row",
"up-to-date":"up to date",
"brand-new":"brand new",
"-hand":" hand",
"open-source":"open source",
"--":"  ",
"dot-py":"dot py",
"-back":" back",
"-th":" th",
"else-if":"<else-if>",
"two-dimensional ":"two dimensional ",
"multi-dimensional":"multi dimensional",
"three-dimensional":"three dimensional",
"one-dimensional":"one dimensional",
"1-dimensional":"1 dimensional",
"2-dimensional":"2 dimensional",
"3-dimensional":"3 dimensional",
"n-dimensional":"n dimensional",
"-oriented ":" oriented ",
"-line ":" line ",
"so-called":"so called",
"-site ":" site ",
"-side":" side",
"trade-offs":"trade offs",
"-separated":" separated",
"-driven":" driven",
"intro-":"introductory",
"Fully-":"Fully ",
"[AUDIO OUT]":" ",
"[1]":" <[1]> ",
"[2]":"<[2]>",
"[]":"<[]>",
"[A]":"<[A]>",
"[B]":"<[B]>",
"[C]":"<[C]>",
"[D]":"<[D]>",
"[E]":"<[E]>",
"[F]":"<[F]>",
"[S]":"<[S]>",
"V-I":"<V-I>",
"low[v]":"<low[v]>",
"low[u]":"<low[u]>",
"(aX + b)":"<(aX + b)>",
"a + b":"<a + b>",
"f(x,y)":"<f(x,y)>",
"f(x)":"<f(x)>",
"f(y)":"<f(y)>",
"f(y | x)":"<f(y | x)>",
"E[X]":"<E[X]>",
"E[Y]":"<E[Y]>",
"X- E[X]":"<X- E[X]>",
"Y- E[Y]":"<Y- E[Y]>",
"fx(vw over w+1)":"<fx(vw over w+1) >",
"fy(v over w+1)":"<fy(v over w+1)>",
"X's":"X",
"i's":"i",
"j's":"j",
"(System.out)":"<(System.out)>",
"(System.in)":"<(System.in)>",
"BRIAN PLANCHER:":"<BRIAN PLANCHER:>",
"VIJAY JANAPA REDDI:":"<VIJAY JANAPA REDDI:>",
"[Narrator] ":"<[Narrator] >",
"Laurence Moroney:":"<Laurence Moroney:>",
"PROFESSOR:":"<PROFESSOR:>",
"Christoph:":"<Christoph:>",
"VIJAY REDDI:":"<VIJAY REDDI:>",
"Marvin:":"<Marvin:>",
"Merel":"<Merel>"
}
for k, v in tokens.items():
    contractions.add(k,v)
# Read in the file
with open('file.txt', 'w') as output_file:
    with open('demofile.txt', 'r') as file :
        for line in file:
            words=[]
            for word in contractions.fix(line).split(' '):                
                if re.match(r"[a-zA-Z]+[0-9]+",word) or re.match(r"[0-9]+[a-zA-Z]+",word):
                    words.append("<"+word+">")
                else:
                    words.append(word)
            output_file.write(" ".join(words))            
            # for word in WhitespaceTokenizer(cont.expand_texts(line)):
                # if word in contractions:
                #     output_file.write(contractions[word])
                # else:
                #     output_file.write(word)
                # output_file.write(" ")

#read a text file
#find contractions
# replace 
#re-write the file